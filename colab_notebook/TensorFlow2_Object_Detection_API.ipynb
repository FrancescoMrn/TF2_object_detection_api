{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF8ysCfYKgTP"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1W_2VdYuIB2WqhB1xvYPhEkl549lXHkzf?usp=sharing)\n",
    "\n",
    "# TF2 Object Detection API\n",
    "\n",
    "This notebook is a simple implementation of the TF2 Object Detection API. \n",
    "It is designed to work out-of-the-box inside google colab. \n",
    "\n",
    "The use of the Colab is suggested when the intention is to deploy a simple detection application quickly. In the case of more complex solutions, it is suggested to train on-premises machines or local GPU machines.\n",
    "\n",
    "This Colab Notebook will:\n",
    "\n",
    "* Install TensorFlow2 Object Detection API and all the required dependencies\n",
    "* Create configuration required configurations and load pre-trained models\n",
    "* Retrain a model to adapt custom models to specific detection classes\n",
    "* Export custom trained model\n",
    "* Perform inference by using the model trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgZLThgZAz6y"
   },
   "source": [
    "# Environment setting up\n",
    "\n",
    "- Connect the notebook to google drive to access training and test dataset\n",
    "- Install Tensorflow 2, TF2 Object Detection API and all the required dependancies\n",
    "- Run TF2 Object Detection API tests to validate the installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P3G2crBB01K"
   },
   "source": [
    "### Connect Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9qc1j1vRz41"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EOtpvlLeS0"
   },
   "source": [
    "### Install TensorFlow2 and the Object Detection API\n",
    "\n",
    "The installation pull the required files from the repository: https://github.com/tensorflow/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypWGYdPlLRUN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QPmVBSlLTzM"
   },
   "outputs": [],
   "source": [
    "# Install Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHfsJ5nWLWh9"
   },
   "outputs": [],
   "source": [
    "# load all the required libraries and dependancies\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import colab_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh_HPMOqWH9z"
   },
   "outputs": [],
   "source": [
    "#run model builder test\n",
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2MAcgJ53STW"
   },
   "source": [
    "# Custom TF2 Object Detection training configuration\n",
    "\n",
    "In this section will be setup the paths to train, test. These two files are required to be .record file. Additionally in this section is required to provide the path to the label map (.pbtxt). \n",
    "\n",
    "Finally the it is required to select the model. In this notebook only some of the most peformant models are reported. Check it out the entire list of models here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "\n",
    "- Provide path to the following files: train.record, test.record and label_map.pbtxt\n",
    "- Select the model that will be later trained on the dataset provided\n",
    "- Create the required configuration files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aUvClvMGVZo"
   },
   "source": [
    "### Provide required path to train, test and label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUd2wtfrqedy"
   },
   "outputs": [],
   "source": [
    "# train_record_fname / test_record_fname: format \"/content/drive/My Drive/<path to the file>/train.record\"\n",
    "train_record_fname = None\n",
    "test_record_fname = None\n",
    "# label_map_pbtxt_fname: format \"/content/drive/My Drive/<path to the file>/label_map.pbtxt\"\n",
    "label_map_pbtxt_fname = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O3WYmhGGcPw"
   },
   "source": [
    "### Select pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN0EUEa3e5Un"
   },
   "outputs": [],
   "source": [
    "# Short-list of models - to discover the entire list of model check tf2_detection_zoo\n",
    "MODELS_CONFIG = {\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 8\n",
    "    },\n",
    "    'efficientdet-d1': {\n",
    "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 8\n",
    "    },\n",
    "    'efficientdet-d2': {\n",
    "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 8\n",
    "    },\n",
    "        'efficientdet-d3': {\n",
    "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frFHmBOuGO0S"
   },
   "outputs": [],
   "source": [
    "MODEL_SELECTED = 'efficientdet-d0' # select your model from MODEL CONFIG dictionary\n",
    "NUM_STEPS = 4000 # The more steps, the longer the training.\n",
    "NUM_EVAL_STEPS = 500 # #Perform evaluation after so many steps\n",
    "\n",
    "\n",
    "model_name = MODELS_CONFIG[MODEL_SELECTED]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[MODEL_SELECTED]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[MODEL_SELECTED]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[MODEL_SELECTED]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kG4TmJUVrYQ7"
   },
   "outputs": [],
   "source": [
    "# download pretrained weights\n",
    "%mkdir /content/models/research/deploy/\n",
    "%cd /content/models/research/deploy/\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-nqYZtdtsgG"
   },
   "outputs": [],
   "source": [
    "# download base training configuration file\n",
    "%cd /content/models/research/deploy\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_ki9jOqxn7V"
   },
   "outputs": [],
   "source": [
    "#prepare\n",
    "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
    "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "    \n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eA5ht3_yukT"
   },
   "outputs": [],
   "source": [
    "#write custom configuration file\n",
    "import re\n",
    "\n",
    "%cd /content/models/research/deploy\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(NUM_STEPS), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    \n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "        \n",
    "    f.write(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMlaN3rs3zLe"
   },
   "outputs": [],
   "source": [
    "# path where the pipeline file is saved \n",
    "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
    "# path where the model training will be saved\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxPj_QV43qD5"
   },
   "source": [
    "# Train Custom TF2 Object Detector\n",
    "\n",
    "In this section the custom model will be trained. \n",
    "The parameters required for training are the following:\n",
    "\n",
    "* pipeline_file: defined above in writing custom training configuration\n",
    "* model_dir: path of tensorboard logs and saved model checkpoints\n",
    "* num_train_steps: number of steps before stopping the training\n",
    "* num_eval_steps: eval on validation set after this many steps\n",
    "\n",
    "*Note: in Google Colab the run is terminated automatically after 12 hrs. Be sure to select Runtime-Change runtime-GPU to speedup the training process.*\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQTfZChVzzpZ"
   },
   "outputs": [],
   "source": [
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={NUM_STEPS} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={NUM_EVAL_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il8bqmrsLE9U"
   },
   "source": [
    "### Tensorboard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI9iCCxoNlAL"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLroOTKhL-C3"
   },
   "source": [
    "# Export custom trained model\n",
    "\n",
    "This section will export the inference graph for later use. \n",
    "\n",
    "*Note: This section is still work in progress*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqaZ4v-vIuDl"
   },
   "outputs": [],
   "source": [
    "# check model weights folder \n",
    "%ls '/content/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnSEZIzl4M10"
   },
   "outputs": [],
   "source": [
    "#run conversion script\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = '/content/fine_tuned_model' # this is the folder where the inference graph will be saved\n",
    "\n",
    "# model weights exporter\n",
    "print(\"Folder where the model is loaded:\",model_dir)\n",
    "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {model_dir} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsE_uVjlsz3u"
   },
   "outputs": [],
   "source": [
    "%ls '/content/fine_tuned_model/saved_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Vz2vJeCCyZR"
   },
   "source": [
    "# Perform inference by using the model trained\n",
    "\n",
    "This last section perfom model inference over the test dataset. We are going to use the following files created durign the configuration and training of the model:\n",
    "\n",
    "- pipeline_file: contains all the manipulation of the input files\n",
    "- model training checkpoint: is the file containing the checkpoint saved during the training \n",
    "- test images path: path to the images to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxtm1NutE5vK"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qs1HJnEhyevJ"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f6DTolSDfXs"
   },
   "outputs": [],
   "source": [
    "%ls '/content/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7qZfrppTcNT"
   },
   "outputs": [],
   "source": [
    "# saved pipeline file\n",
    "pipeline_config = pipeline_file\n",
    "\n",
    "# generally you want to put the last ckpt from training\n",
    "model_dir = '/content/training/ckpt-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTvYPXeRTwcU"
   },
   "outputs": [],
   "source": [
    "def get_model_detection_function(model):\n",
    "  \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "  @tf.function\n",
    "  def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = model.preprocess(image)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "  return detect_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFY75DfTDHaU"
   },
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "ckpt.restore(os.path.join(model_dir))\n",
    "\n",
    "# get model function\n",
    "detect_fn = get_model_detection_function(detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ycfl7rnDT1D"
   },
   "outputs": [],
   "source": [
    "#map labels for inference decoding\n",
    "label_map_path = configs['eval_input_config'].label_map_path\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN1BzORoIzV4"
   },
   "outputs": [],
   "source": [
    "#run detector\n",
    "import random\n",
    "\n",
    "# TEST_IMAGE_PATHS format: \"/content/drive/My Drive/<path to the folder>/*.jpg\"\n",
    "TEST_IMAGE_PATHS = glob.glob(None)\n",
    "image_path = random.choice(TEST_IMAGE_PATHS)\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# Small data manipulation\n",
    "# Flip horizontally\n",
    "# image_np = np.fliplr(image_np).copy()\n",
    "# Convert image to grayscale\n",
    "# image_np = np.tile(\n",
    "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(\n",
    "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'][0].numpy(),\n",
    "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "      detections['detection_scores'][0].numpy(),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=.5,\n",
    "      agnostic_mode=False,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlow2-Object-Detection-API.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
